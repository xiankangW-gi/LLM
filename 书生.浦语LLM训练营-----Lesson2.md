# 书生.浦语LLM训练营-----Lesson2

## code

### 环境准备

```python
#克隆开发环境
bash
conda create --name internlm-demo --clone=/root/share/conda_envs/internlm-base
#激活
conda activate internlm-demo
#安装依赖
python -m pip install --upgrade pip

pip install modelscope==1.9.5
pip install transformers==4.35.2
pip install streamlit==1.24.0
pip install sentencepiece==0.1.99
pip install accelerate==0.24.1
```

### 模型下载

```python
import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer
import os
model_dir = snapshot_download('Shanghai_AI_Laboratory/internlm-chat-7b', cache_dir='/root/model', revision='v1.0.3')
```













## hugging face

```python
import torch
from modelscope import snapshot_download, AutoModel, AutoTokenizer
import os

os.system('huggingface-cli download --resume-download internlm/internlm-chat-7b --local-dir root/model/test/')

from huggingface_hub import hf_hub_download  # Load model directly 

hf_hub_download(repo_id="internlm/internlm-7b", filename="config.json")
```





![image-20240311213552425](C:\Users\wangx\AppData\Roaming\Typora\typora-user-images\image-20240311213552425.png)